# Biomechanical Analyzer

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python](https://img.shields.io/badge/python-3.10%2B-blue)

A computer vision and machine learning-based system designed to evaluate the biomechanical precision of strength exercises. This application helps gym users improve their technique and reduce the risk of injuries through pose estimation and feedback.

---

## ğŸš€ Project Overview

**Purpose:**  
To develop a web-based prototype capable of analyzing exercise performance and providing visual and textual feedback based on biomechanical standards.

---

## ğŸ§  Key Features

- 2D pose estimation using **MediaPipe**
- Biomechanical analysis of the **squat** exercise
- Trained machine learning model to classify correct vs incorrect execution
- Visual (skeleton overlay) and textual feedback

---

## ğŸ›  Tech Stack

- **Python 3.10+**
- **MediaPipe** â€“ Pose estimation
- **OpenCV** â€“ Video processing
- **scikit-learn / -** â€“ ML model training
- **Jupyter Notebooks** â€“ EDA, model training & evaluation

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ LICENSE            <- License of the project
â”œâ”€â”€ HISTORY.md         <- The HISTORY changes track
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
|
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py            <- Main script for running the processing pipeline
|
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ models/            <- Trained and serialized models, model predictions, or model summaries
â”‚   â”œâ”€â”€ trained/       <- Final machine learning models ready for inference (e.g., .pkl, .joblib)
â”‚   â”œâ”€â”€ checkpoints/   <- Intermediate model weights saved during training (e.g., for resuming)
â”‚   â””â”€â”€ mediapipe/     <- Pretrained task models used by MediaPipe (e.g., pose_landmarker.task)
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks for exploration, training, and evaluation
â”‚                         Naming: <order>-<initials>-<description>.ipynb, e.g. 1.0-lea-exploration.ipynb
â”‚
â”‚
â”œâ”€â”€ references         <- Background material and references.
â”‚   â”œâ”€â”€ biomechanics.md       # Biomechanics notes and theory
â”‚   â””â”€â”€ papers/               # Academic sources or research papers (PDF, links)
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â””â”€â”€ analyzer           <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Marks this directory as a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Data loading and preprocessing logic
    â”‚
    â”œâ”€â”€ features.py             <- Feature extraction functions
    â”‚
    â”œâ”€â”€ plots.py                <- Visualization utilities
    â”‚
    â”œâ”€â”€ modeling                <- Machine learning pipeline 
    â”‚   â”œâ”€â”€ __init__.py 
    â”‚   â”œâ”€â”€ train.py            <- Model training script
    â”‚   â””â”€â”€ predict.py          <- Model inference and predictions
    |
    â”œâ”€â”€ vision                  <- OpenCV + MediaPipe
    |   â”œâ”€â”€ extract_keypoints.py
    â”‚   â””â”€â”€ preprocess_video.py
    |
    â””â”€â”€ api                     <- FastAPI backend module (to be implemented)
```

---

## ğŸš§ Scope of the Project (v0.1.0)

**Included:**
- Evaluation of a single exercise (squat) in controlled environments
- 2D analysis and model feedback
- Functional prototype and notebooks

**Excluded:**
- Real-time multi-user detection
- 3D pose estimation
- Database integration or user login

---

## ğŸ“Š Metrics & Objectives

- Reduce technical errors during squat execution
- Improve similarity with optimal biomechanical patterns
- Increase the percentage of properly executed repetitions

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/Raulinho-A/biomechanical-analyzer.git
cd biomechanical-analyzer
pip install -r requirements.txt
```

## ğŸ§ª Run
```bash
python main.py
```
Or explore the system via the Jupyter notebooks under notebooks/.

## ğŸ“„ License
This project is licensed under the MIT License.

